## LVM

 하드디스크를 분할한다. 주요 용도는 여러 개의 하드디스크를 합쳐서 1개의 파티션으로 구성 후, 다시 필요에 따라 나누는 것. 일례로 2TB의 하드디스크 2개를 합치고 다시 1TB와 3TB로 나눠서 사용

* 물리 볼륨(Physical Volume): /dev/sda1, /dev/sdb1 등의 파티션
* 볼륨 그룹(Volume Group): 물리 볼륨을 합쳐서 1개의 물리 그륩으로 만든 것.
* 논리 볼륨(Logical Volume): 볼륨 그룹을 1개 이상으로 나눈 것으로 논리적 그룹이라고도 함

### 1. SCSI 하드디스크 3GB, 2GB 로 두 개 만들기

### 2. 파티션 할당 및 볼륨 그룹 만들기

```
//파티션 할등
#fdisk /dev/sdb

Command: n
Select : p
Partition number (1-4) : 1
First sector : Enter
Last sector : Enter
Command : t
Hex Code: 8e
Command: p
Command: w

//볼륨 그룹 만들기
pvcreate /dev/sdb1						//물리그룹 생성
pvcreate /dev/sdc1
vgcreate myVG /dev/sdb1 /dev/sdc1		//볼륨그룹 생성
vgdisplay								//볼륨그룹 생성 확인
```



### 3.  논리그룹 생성

```
lvcreate --size 1G --name myLG1 myVG				//myVG 아래 myLG1을 1GB로 생성
lvcreate --size 3G --name myLG2 myVG
lvcreate --extents 100%FREE --name myLG3 myVG		//나머지 용량 모두 할당
```

### 4. 포맷

```
mkfs.ext4 /dev/myVG/myLG1
mkfs.ext4 /dev/myVG/myLG2
mkfs.ext4 /dev/myVG/myLG3
```

### 5. 새 디렉터리 생성 및 마운트

```
mkdir /lvm1 /lvm2 /lvm3
mount /dev/myVG/myLG1 /lvm1
mount /dev/myVG/myLG2 /lvm2
mount /dev/myVG/myLG3 /lvm3

```

### 6. 컴퓨터를 켤 때 항상 마운트 되도록

```
#vi /etc/fstab
/dev/myVG/myLG1 /lvm1 ext4 defaults 0 0
/dev/myVG/myLG2 /lvm2 ext4 defaults 0 0
/dev/myVG/myLG3 /lvm3 ext4 defaults 0 0
```





## Hadoop



### 1. 네트워크 설정

서버 만들 때, NAT 들어가서 Advanced ->  Generate 필수

```
systemctl stop firewalld
systemctl disable firewalld

cd /etc/sysconfig/network-scripts/
vi ifcfg-ens32

// ip 변경
systemctl restart network					// 네트워크 재시작
ifconfig									// 바뀌었는지 확인

```



### 2. 호스트 네임 바꾸기

```
hostnamectl set-hostname 서버이름

vi /etc/hosts

// 192.168.111.101 서버이름 
```



### 3. jdk 설치

```
download linux jdk x64
cd 다운로드
tar xvf jdk...tar.gz
mv jdk1.8.0_261 jdk1.8.0
cp -r jdk1.8.0 /usr/local
cd /usr/bin
ln -s /usr/local/jdk1.8.0/bin/java java
ls -l java


```



### 4. hadoop 설치

```
cd 다운로드
wget https://archive.apache.org/dist/hadoop/common/hadoop-1.2.1/hadoop-1.2.1.tar.gz
tar xvf hadoop-1.2.1.tar.gz
cp -r hadoop-1.2.1 /usr/local
vi /etc/profile 

	 52	JAVA_HOME=/usr/local/jdk1.8.0
     53 CLASSPATH=/usr/local/jdk1.8.0/lib
     54 HADOOP_HOME=/usr/local/hadoop-1.2.1
     55 export JAVA_HOME CLASSPATH HADOOP_HOME
     56 PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:.:$PATH
     
     
source /etc/profile					// 변경된 profile을 시스템에 적용
```

- JAVA_HOME=/usr/local/jdk1.8.0:	/usr/local/jdk1.8.0을 JAVA_HOME로 정의하겠다.

- CLASSPATH=/usr/local/jdk1.8.0/lib:	/usr/local/jdk1.8.0/lib를 CLASSPATH로 정의하겠다.

- HADOOP_HOME=/usr/local/hadoop-1.2.1:	/usr/local/hadoop-1.2.1을 HADOOP_HOME이라고 정의하겠다.

즉, 위의 3개는 그냥 파일이름을 재정의한 것(책에서 말하는 '환경변수'). 이름은 내 마음대로 해도 됨

- export JAVA_HOME CLASSPATH HADOOP_HOME: 위에서 정의한 3개의 파일을 export하겠다.
- PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:.:$PATH (타이포라 특성으로 인해 저렇게 나옴 마우스로 클릭해보자) : PATH 변수 재정의

### 5. 보안 설정

``` 
ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa			//아무데서나 실행가능
cd .ssh
cat id_dsa.pub >> authorized_keys

cd .ssh
ls
```

![image-20200922200236471](C:%5CUsers%5Cuser%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200922200236471.png)



### 6. configuration

- core-site.xml

```
<configuration>
<property>
<name>fs.default.name</name>
<value>hdfs://localhost:9000</value>
</property>
<property>
<name>hadoop.tmp.dir</name>
<value>/usr/local/hadoop-1.2.1/tmp</value>
</property>
</configuration>
```

- hdfs-site.xml

```
<configuration>
<property>
<name>dfs.replication</name>
<value>1</value> 
</property>
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.name.dir</name>
<value>/usr/local/hadoop-1.2.1/name</value>
</property>
<property>
<name>dfs.data.dir</name>
<value>/usr/local/hadoop-1.2.1/data</value>
</property>
</configuration>
```

* mapred-site.xml

```
<configuration>
<property>
<name>mapred.job.tracker</name>
<value>localhost:9001</value>
</property>
</configuration>
```



* hadoop-env.sh

```
9 export JAVA_HOME=/usr/local/jdk1.8.0		(변경)

10 export HADOOP_HOME_WARN_SUPPRESS="TRUE"	(추가)
-> 하둡 재구동시
Warning: $HADOOP_HOME is deprecated. 라는 에러가 뜨는 것을 방지
```



### 6. Hadoop 실행

```
hadoop namenode -format
start-all.sh
	<성공한다면>
starting namenode, logging to /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-root-namenode-mainserver.out
localhost: starting datanode, logging to /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-root-datanode-hadoop.out
localhost: starting secondarynamenode, logging to /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-root-secondarynamenode-hadoop.out
starting jobtracker, logging to /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-root-jobtracker-mainserver.out
localhost: starting tasktracker, logging to /usr/local/hadoop-1.2.1/libexec/../logs/hadoop-root-tasktracker-hadoop.out

jps
3825 NameNode
4162 JobTracker
4279 TaskTracker
4072 SecondaryNameNode
4395 Jps
3950 DataNode


```

파이어폭스 들어가서 [http://hadoopserver:50070](http://hadoopserver:50070/)



### 7. Test

```
cd /usr/local/hadoop-1.2.1
hadoop fs -mkdir /test
hadoop fs -put README.txt /test
hadoop jar hadoop-examples-1.2.1.jar wordcount /test /output
```

파이어폭스 [http://hadoopserver:50070](http://hadoopserver:50070/) 로 들어가서 확인하면

![](C:%5CUsers%5Cuser%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200922201553601.png)

![image-20200922201846498](C:%5CUsers%5Cuser%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200922201846498.png)

![image-20200922201913443](C:%5CUsers%5Cuser%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200922201913443.png)

### ※ 내가 에러 걸렸던 부분

![image-20200922200128169](C:%5CUsers%5Cuser%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200922200128169.png)

해결방안: 그냥 hdfs-site.xml 가서 다시 쓴다. 잘못 쓴 거니까 눈빠지게 찾지 말기!





다른 에러사항

1. 명령을 찾을 수 없습니다.
   * /usr/local/hadoop-1.2.1/bin에 무언가 있어야한다.

