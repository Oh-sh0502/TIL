# # 20200924

### 1. hadoop 서버에 Hadoop 과 Mysql 실행

hadoop과 Mysql이 다운받아져 있다는 가정하에 실시. 

* hadoop 실행

```
start-all.sh
jps
	4147 DataNode
	4986 Jps
	4027 NameNode
	4283 SecondaryNameNode
	4492 TaskTracker
	4365 JobTracker
// 위와 같이 jps에 대해 6개의 결과가 나와야함 하나라도 부족하면
stop-all.sh
start-all.sh 
반복
```

* mysql(Mariadb) 실행 및 hive 계정, database 만들기

```
systemctl restart mysql
systemctl status mysql
chkconfig mysql on 			// 껏다 켜도 mysql 켜질 수 있게

mysqladmin -u root password '111111'
mysql -h localhost -u root -p
Enter password: 111111 입력
	// 접속완료
	use mysql;
	GRANT ALL ON *.* TO hive@'127.0.0.1' IDENTIFIED BY '111111';
	GRANT ALL ON *.* TO hive@'localhost' IDENTIFIED BY '111111';
	GRANT ALL ON *.* TO hive@'192.168.111.120' IDENTIFIED BY '111111';
	GRANT ALL ON *.* TO hive@'hadoop' IDENTIFIED BY '111111';
	quit;
mysql -h localhost -u hive -p
	CREATE DATABASE hive_db;
```



### 2. HIVE 설치

```
cd /usr/local
wget https://archive.apache.org/dist/hive/hive-1.0.1/apache-hive-1.0.1-bin.tar.gz
tar xvf apache-hive-1.0.1-bin.tar.gz
mv apache-hive-1.0.1-bin hive
vi /etc/profile
	JAVA_HOME=/usr/local/jdk1.8.0
	CLASSPATH=/usr/local/jdk1.8.0/lib
	HADOOP_HOME=/usr/local/hadoop-1.2.1
	HIVE_HOME=/usr/local/hive
	export JAVA_HOME CLASSPATH HADOOP_HOME HIVE_HOME
	PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin:.:$PATH

// 카페에서 mariadb-java-client-1.3.5.jar를 다운로드
// /usr/local/hive/lib 에 복사
cp mariadb-java-client-1.3.5.jar /usr/local/hive/lib

vi /usr/local/hive/conf/hive-site.xml
	<?xml version="1.0"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	<configuration>
    	<property>
       		<name>hive.metastore.local</name>
        	<value>false</value>
       		<description>controls whether to connect to remove metastore server or open a new metastore server in Hive Client JVM</description>
   		</property>
   		<property>
        	<name>javax.jdo.option.ConnectionURL</name>
        	<value>jdbc:mariadb://localhost:3306/hive_db?createDatabaseIfNotExist=true</value>
        	<description>JDBC connect string for a JDBC metastore</description>
    	</property>
  		<property>
        	<name>javax.jdo.option.ConnectionDriverName</name>
        	<value>org.mariadb.jdbc.Driver</value>
        	<description>Driver class name for a JDBC metastore</description>
    	</property>
    	<property>
        	<name>javax.jdo.option.ConnectionUserName</name>
        	<value>hive</value>
        	<description>username to use against metastore database</description>
    	</property>
    	<property>
        	<name>javax.jdo.option.ConnectionPassword</name>
        	<value>111111</value>
        	<description>password to use against metastore database</description>
   		</property>
	</configuration>

//HIVE DIRECTORY SETTING
hadoop fs -mkdir /tmp
hadoop fs -mkdir /user/root/warehouse
hadoop fs -chmod 777 /tmp
hadoop fs -chmod 777 /user/root/warehouse
hadoop fs -mkdir /tmp/hive
hadoop fs -chmod 777 /tmp/hive
```



### 3. HIVE 예제

```mysql
// 사전준비: 카페 글 'HIVE 예제'에서 hdi-data.csv를 다운받는다.
cd 다운로드
mv hdi-data.csv /root
mv hdi-data.csv hdi.txt

hive

// 데이터 테이블 작성 및 파일 업로드
hive> CREATE TABLE HDI(id INT, country STRING, hdi FLOAT, lifeex INT, mysch INT, eysch INT, gni INT) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE;

hive>load data local inpath '/root/hdi.txt' OVERWRITE into table HDI;

	Loading data to table default.hdi
	Table default.hdi stats: [numFiles=1, numRows=0, totalSize=9189, rawDataSize=0]
	OK
	Time taken: 0.943 seconds

hive> select * from hdi limit 5;
	OK
	NULL		NULL	NULL	NULL	NULL	NULL
	1	Norway	0.943	81	12	17	47557
	2	Australia	0.929	81	12	18	34431
	3	Netherlands	0.91	80	11	16	36402
	4	United States	0.91	78	12	16	43017
	Time taken: 0.119 seconds, Fetched: 5 row(s)


```

```
// Java Application 연동
hive 서버 실행 - Java 프로그램이 접속 할 수 있는 Deamon을 실행
Hive 2.x 버전에서는 hiveserver2로 기동하고, 따라서 스키마를 hive2로 지정해서 열어야 한다.
[root]#hive --service hiveserver2	
// 연결되었다는 코드
20/09/24 19:18:08 WARN conf.HiveConf: DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
20/09/24 19:18:08 WARN conf.HiveConf: HiveConf of name hive.metastore.local does not exist
```

[카페](https://cafe.naver.com/multiiot2020)에서 hivelibs.zip 을 다운로드 후 압축을 풀어놓는다.

이클립스에서 Project를 선택하고 

Properties -> Java Build Path -> libraries -> Add External JARS...

압축 푼 거 전부 넣는다.

```java
package d01;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.ResultSet;

public class HiveTest {

	public static void main(String[] args) throws Exception{
		String url = "jdbc:hive2://192.168.111.120:10000/default";
		String id = "root";
		String password ="111111";
		Class.forName("org.apache.hive.jdbc.HiveDriver");
		Connection con = DriverManager.getConnection(url, id, password);
		PreparedStatement pstmt = con.prepareStatement("SELECT * FROM HDI");
		ResultSet rset = pstmt.executeQuery();
		while(rset.next()) {
			String s1 = rset.getString(1);
			String s2 = rset.getString(2);
			String s3 = rset.getString(3);
			System.out.println(s1+" "+s2+" "+s3);
		}
		con.close();
	}
}
// Ctrl+f11로 실행 
```



### 4. HIVE 예제 2

```
// 테이블 생성(총 29개의 칼럼)
CREATE TABLE airline_delay(
Year INT,
MONTH INT,
DayofMonth INT,
DayofWeek INT,
DepTime INT,
CRSDepTime INT,
ArrTime INT,
CRSArrTime INT,
UniqueCarrier STRING,
FlightNum INT,
TailNum STRING,
ActualElapsedTime INT,
CRSElapsedTime INT,
AirTime INT,
ArrDelay INT,
DepDelay INT,
Origin STRING,
Dest STRING,
Distance INT,
TaxiIn INT,
TaxiOut INT,
Cancelled INT,
CancellationCode STRING COMMENT 'A = carrier, B = weather, C = NAS, D = security',
Diverted INT COMMENT '1 = yes, 0 = no',
CarrierDelay STRING,
WeatherDelay STRING,
NASDelay STRING,
SecurityDelay STRING,
LateAircraftDelay STRING)
COMMENT 'TEST DATA'
PARTITIONED BY (delayYear INT)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
STORED AS TEXTFILE;
```

- CREATE TABLE 테이블(칼럼명 칼럼 타입, ...): 테이블 생성
- COMMENT 'The data consists of ... ' : 테이블의 설명을 참고용으로 등록하는 부분
- PARTITIONED BY (delayTear INT): 테이블의 파티션을 설정하는 부분. 파티션을 설정하면 해당 테이블의 데이터를 파티션별로 디렉터리를 생성해서 저장하게 된다.
- ROW FORMAT: 해당 테이블 내의 데이터가 어떠한 형식으로 저장되는지 설정
  - FIELDS TERMINATED BY ',': 필드를 콤마로 구분
  - LINES TERMINATED BY '\n': 행과 행은 \n값으로 구분
- STORED AS: 데이터 저장 파일 포맷을 의미. 지원하는 저장 포맷은 두가지다.
  - TEXTFILE: 텍스트파일
  - SEQUENCEFILE: 시퀀스파일

 

```
// DESCRIBE: 테이플 칼럼을 볼 수 있다. 
DESCRIBE airline_delay;

// ALTER TABLE: 테이블 수정
ALTER TABLE airline_delay RENAME TO delay_statics;				// 테이블명 변경
ALTER TABLE delay_statics ADD COLUMNS (delayMonth STRING);		// 컬럼 추가

// DROP TABLE: 테이블 삭제
DROP TABLE delay_statics;
```



#### 데이터 업로드

[2006.csv](https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/HG7NV7/EPIFFT)	[2007.csv](https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/HG7NV7/EPIFFT)	[2008.csv](https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/HG7NV7/EIR0RA)

세 파일을 모두 다운로드 받는다.  

```
cd 다운로드
bzip2 -d 2006.csv.bz2
bzip2 -d 2007.csv.bz2
bzip2 -d 2008.csv.bz2
mv 2006.csv /root
mv 2007.csv /root
mv 2008.csv /root

//hive 접속
hive
LOAD DATA LOCAL INPATH '/root/2006.csv' OVERWRITE INTO TABLE airline_delay PARTITION (delayYear='2006');
LOAD DATA LOCAL INPATH '/root/2007.csv' OVERWRITE INTO TABLE airline_delay PARTITION (delayYear='2007');
LOAD DATA LOCAL INPATH '/root/2008.csv' OVERWRITE INTO TABLE airline_delay PARTITION (delayYear='2008');


// 데이터 조회하기
SELECT year, month, deptime, arrtime, uniquecarrier, flightnum FROM airline_delay WHERE delayYear = '2008' LIMIT 10;
```



#### 집계 함수

```
//미국 항공 운항 지연 데이터 중 2006 년도의 지연 건수 조회
SELECT COUNT(1) FROM airline_delay WHERE delayYear =2006;

//미국 항공 운항 지연 데이터 중 2006년도 월별 도착 지연 건수 조회
SELECT Year, Month, COUNT(*) AS arrive_delay_count FROM airline_delay WHERE delayYear = 2006 AND ArrDelay > 0 GROUP BY Year, Month;

// 2006년도 월별 평균 지연 시간
SELECT Year, Month, AVG(ArrDelay) AS avg_arrive_delay_time, AVG(DepDelay) AS avg_departure_delay_time FROM airline_delay WHERE delayYear = 2006 AND ArrDelay > 0 GROUP BY Year, Month;
```

